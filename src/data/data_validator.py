import pandas as pd
import numpy as np
import logging
from typing import List, Dict, Tuple


class DataValidator:
    """Validador e limpador de dados hist√≥ricos"""

    @staticmethod
    def validate_data(df: pd.DataFrame) -> Tuple[bool, List[str]]:
        """Valida qualidade dos dados hist√≥ricos"""

        issues = []

        if df is None or df.empty:
            return False, ["Dados vazios ou nulos"]

        # 1. Verificar colunas obrigat√≥rias
        required_columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            issues.append(f"Colunas faltantes: {missing_columns}")

        # 2. Verificar dados faltantes
        missing_data = df[required_columns].isnull().sum()
        if missing_data.any():
            issues.append(f"Dados faltantes: {missing_data.to_dict()}")

        # 3. Verificar consist√™ncia OHLC
        invalid_ohlc = df[
            (df['high'] < df['low']) |
            (df['high'] < df['open']) |
            (df['high'] < df['close']) |
            (df['low'] > df['open']) |
            (df['low'] > df['close'])
            ]
        if not invalid_ohlc.empty:
            issues.append(f"OHLC inconsistente em {len(invalid_ohlc)} registros")

        # 4. Verificar pre√ßos positivos
        if (df[['open', 'high', 'low', 'close']] <= 0).any().any():
            issues.append("Pre√ßos n√£o positivos detectados")

        # 5. Verificar volume
        if (df['volume'] < 0).any():
            issues.append("Volume negativo detectado")

        # 6. Verificar duplicatas de timestamp
        duplicates = df.duplicated(subset=['timestamp']).sum()
        if duplicates > 0:
            issues.append(f"Timestamps duplicados: {duplicates}")

        # 7. Verificar ordem temporal
        if not df['timestamp'].is_monotonic_increasing:
            issues.append("Dados n√£o est√£o em ordem cronol√≥gica")

        # 8. Verificar outliers extremos
        price_changes = df['close'].pct_change().abs()
        extreme_changes = (price_changes > 0.5).sum()  # Mudan√ßas > 50%
        if extreme_changes > len(df) * 0.01:  # Mais de 1%
            issues.append(f"Muitos outliers extremos: {extreme_changes}")

        return len(issues) == 0, issues

    @staticmethod
    def clean_data(df: pd.DataFrame, aggressive: bool = False) -> pd.DataFrame:
        """Limpa e trata dados hist√≥ricos"""

        if df is None or df.empty:
            return df

        logging.info(f"üßπ Limpando dados: {len(df)} registros iniciais")
        original_length = len(df)

        # 1. Remover duplicatas
        df = df.drop_duplicates(subset=['timestamp'])
        if len(df) < original_length:
            logging.info(f"   Removidas {original_length - len(df)} duplicatas")

        # 2. Ordenar por timestamp
        df = df.sort_values('timestamp').reset_index(drop=True)

        # 3. Remover registros com OHLC inv√°lido
        invalid_mask = (
                (df['high'] < df['low']) |
                (df['high'] < df['open']) |
                (df['high'] < df['close']) |
                (df['low'] > df['open']) |
                (df['low'] > df['close']) |
                (df[['open', 'high', 'low', 'close']] <= 0).any(axis=1)
        )

        if invalid_mask.any():
            df = df[~invalid_mask]
            logging.info(f"   Removidos {invalid_mask.sum()} registros com OHLC inv√°lido")

        # 4. Tratar volume zero/negativo
        df.loc[df['volume'] <= 0, 'volume'] = df['volume'].median()

        # 5. Tratar outliers extremos
        if aggressive:
            price_changes = df['close'].pct_change().abs()
            outlier_mask = price_changes > 0.3  # Mudan√ßas > 30%

            if outlier_mask.any():
                df = df[~outlier_mask]
                logging.info(f"   Removidos {outlier_mask.sum()} outliers extremos")

        # 6. Interpolar dados faltantes (limitado)
        numeric_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in numeric_columns:
            if df[col].isnull().any():
                df[col] = df[col].interpolate(method='linear', limit=3)

        # 7. Remover registros ainda com NaN
        df = df.dropna()

        # 8. Reset index
        df = df.reset_index(drop=True)

        logging.info(f"‚úÖ Limpeza conclu√≠da: {len(df)} registros finais")

        return df

    @staticmethod
    def detect_gaps(df: pd.DataFrame, expected_interval_minutes: int) -> List[Dict]:
        """Detecta gaps temporais nos dados"""

        if df.empty:
            return []

        df['time_diff'] = df['timestamp'].diff()
        expected_diff = pd.Timedelta(minutes=expected_interval_minutes)

        # Gaps maiores que 2x o intervalo esperado
        large_gaps = df[df['time_diff'] > expected_diff * 2]

        gaps = []
        for idx, row in large_gaps.iterrows():
            if idx > 0:
                gaps.append({
                    'start_time': df.iloc[idx - 1]['timestamp'],
                    'end_time': row['timestamp'],
                    'duration': row['time_diff'],
                    'expected_duration': expected_diff,
                    'gap_ratio': row['time_diff'] / expected_diff
                })

        return gaps

    @staticmethod
    def get_data_quality_report(df: pd.DataFrame) -> Dict:
        """Gera relat√≥rio de qualidade dos dados"""

        if df.empty:
            return {"error": "Dados vazios"}

        # Estat√≠sticas b√°sicas
        total_records = len(df)
        date_range = df['timestamp'].max() - df['timestamp'].min()

        # Verificar completude
        missing_data = df.isnull().sum()
        completeness = (1 - missing_data.sum() / (len(df) * len(df.columns))) * 100

        # Verificar consist√™ncia
        is_valid, issues = DataValidator.validate_data(df)

        # Estat√≠sticas de pre√ßo
        price_stats = {
            'min_price': df['close'].min(),
            'max_price': df['close'].max(),
            'mean_price': df['close'].mean(),
            'price_volatility': df['close'].pct_change().std()
        }

        # Estat√≠sticas de volume
        volume_stats = {
            'min_volume': df['volume'].min(),
            'max_volume': df['volume'].max(),
            'mean_volume': df['volume'].mean(),
            'zero_volume_count': (df['volume'] == 0).sum()
        }

        return {
            'total_records': total_records,
            'date_range_days': date_range.days,
            'start_date': df['timestamp'].min(),
            'end_date': df['timestamp'].max(),
            'completeness_pct': completeness,
            'is_valid': is_valid,
            'issues': issues,
            'price_stats': price_stats,
            'volume_stats': volume_stats
        }